{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AlphaEarth Uzbekistan Comprehensive Environmental Analysis\n",
    "\n",
    "**A Research-Grade Environmental Assessment Pipeline**\n",
    "\n",
    "This notebook provides a comprehensive environmental analysis of Uzbekistan using AlphaEarth satellite embeddings and advanced machine learning techniques. The analysis covers seven key environmental domains:\n",
    "\n",
    "1. **Soil Moisture Analysis** - Water stress assessment and vulnerability mapping\n",
    "2. **Afforestation Planning** - Site suitability modeling and species selection\n",
    "3. **Land Degradation Assessment** - Hotspot identification and trend analysis\n",
    "4. **Riverbank Disturbance Analysis** - Buffer zone monitoring and change detection\n",
    "5. **Protected Area Monitoring** - Conservation status and incident detection\n",
    "6. **Biodiversity Analysis** - Ecosystem classification and fragmentation assessment\n",
    "7. **Urban Heat Analysis** - Heat island modeling and mitigation strategies\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "1. [Setup and Configuration](#setup)\n",
    "2. [Data Overview](#overview)\n",
    "3. [Individual Module Analyses](#modules)\n",
    "4. [Synthesis and Integration](#synthesis)\n",
    "5. [Quality Assurance](#qa)\n",
    "6. [Results and Recommendations](#results)\n",
    "7. [Export and Documentation](#export)\n",
    "\n",
    "---\n",
    "\n",
    "## Requirements\n",
    "- Python 3.10+\n",
    "- All dependencies from `requirements.txt`\n",
    "- Sufficient disk space for analysis outputs (~500MB)\n",
    "\n",
    "## Usage\n",
    "Run all cells sequentially or use \"Run All\" to execute the complete analysis pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration {#setup}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set up paths\n",
    "current_dir = Path.cwd()\n",
    "project_root = current_dir / 'alphaearth-uz'\n",
    "src_path = project_root / 'src'\n",
    "\n",
    "# Add source path to Python path\n",
    "if str(src_path) not in sys.path:\n",
    "    sys.path.insert(0, str(src_path))\n",
    "\n",
    "# Change to project directory\n",
    "os.chdir(project_root)\n",
    "\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"Source path: {src_path}\")\n",
    "print(f\"Current working directory: {os.getcwd()}\")\n",
    "print(f\"Python version: {sys.version}\")\n",
    "\n",
    "# Import AlphaEarth modules\n",
    "try:\n",
    "    from aeuz import orchestrator\n",
    "    from aeuz.utils import load_config, setup_plotting\n",
    "    print(\"✅ AlphaEarth modules imported successfully\")\n",
    "except ImportError as e:\n",
    "    print(f\"❌ Error importing AlphaEarth modules: {e}\")\n",
    "    print(\"Please ensure you're running from the correct directory\")\n",
    "\n",
    "# Set up plotting configuration\n",
    "setup_plotting()\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"🌍 AlphaEarth Uzbekistan Analysis Environment Ready\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration and Data Overview {#overview}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration\n",
    "config = load_config()\n",
    "print(\"📋 Analysis Configuration:\")\n",
    "print(f\"   Country: {config['country']}\")\n",
    "print(f\"   Regions: {', '.join(config['regions'])}\")\n",
    "print(f\"   Time window: {config['time_window'][0]} - {config['time_window'][1]}\")\n",
    "print(f\"   CRS: {config['crs']}\")\n",
    "print(f\"   Random seed: {config['random_seed']}\")\n",
    "\n",
    "# Analysis modules available\n",
    "modules = [\n",
    "    \"soil_moisture\",\n",
    "    \"afforestation\", \n",
    "    \"degradation\",\n",
    "    \"riverbank\",\n",
    "    \"protected_areas\",\n",
    "    \"biodiversity\",\n",
    "    \"urban_heat\",\n",
    "    \"synthesis\",\n",
    "    \"qa_module\",\n",
    "    \"publish\"\n",
    "]\n",
    "\n",
    "print(f\"\\n🔬 Available Analysis Modules ({len(modules)}):\")\n",
    "for i, module in enumerate(modules, 1):\n",
    "    print(f\"   {i:2d}. {module.replace('_', ' ').title()}\")\n",
    "\n",
    "# Expected outputs\n",
    "expected_outputs = {\n",
    "    'tables': 'CSV data tables with analysis results',\n",
    "    'figs': 'High-resolution research plots and visualizations', \n",
    "    'data_final': 'GeoJSON files for geographic data',\n",
    "    'reports': 'Synthesis and executive summary reports',\n",
    "    'qa': 'Quality assurance reports and validation'\n",
    "}\n",
    "\n",
    "print(f\"\\n📁 Expected Output Categories:\")\n",
    "for category, description in expected_outputs.items():\n",
    "    print(f\"   • {category}: {description}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Individual Module Analyses {#modules}\n",
    "\n",
    "This section runs each analysis module individually and displays key results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Soil Moisture Analysis\n",
    "\n",
    "Comprehensive water stress assessment using machine learning prediction models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aeuz import soil_moisture\n",
    "\n",
    "print(\"🌊 Running Soil Moisture Analysis...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "soil_results = soil_moisture.run()\n",
    "\n",
    "print(\"\\n📊 Soil Moisture Analysis Summary:\")\n",
    "if 'summary_stats' in soil_results:\n",
    "    stats = soil_results['summary_stats']\n",
    "    print(f\"   • National average moisture: {stats['national_avg_moisture']:.3f}\")\n",
    "    print(f\"   • Severe stress areas: {stats['severe_stress_areas']} sites\")\n",
    "    print(f\"   • High stress areas: {stats['high_stress_areas']} sites\")\n",
    "    print(f\"   • Model R²: {stats['model_r2']:.3f}\")\n",
    "    print(f\"   • Model RMSE: {stats['model_rmse']:.3f}\")\n",
    "\n",
    "print(f\"\\n✅ Generated {len(soil_results['artifacts'])} output files\")\n",
    "for artifact in soil_results['artifacts'][:3]:  # Show first 3\n",
    "    print(f\"   • {artifact}\")\n",
    "if len(soil_results['artifacts']) > 3:\n",
    "    print(f\"   ... and {len(soil_results['artifacts'])-3} more\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Afforestation Suitability Analysis\n",
    "\n",
    "Site selection and species recommendation using environmental modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aeuz import afforestation\n",
    "\n",
    "print(\"🌳 Running Afforestation Suitability Analysis...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "afforestation_results = afforestation.run()\n",
    "\n",
    "print(\"\\n📊 Afforestation Analysis Summary:\")\n",
    "if 'summary_stats' in afforestation_results:\n",
    "    stats = afforestation_results['summary_stats']\n",
    "    print(f\"   • Total suitable sites: {stats['total_suitable_sites']}\")\n",
    "    print(f\"   • Average suitability: {stats['avg_suitability_score']:.3f}\")\n",
    "    print(f\"   • Priority sites: {stats['priority_sites']}\")\n",
    "    print(f\"   • Binary model AUC: {stats['model_auc']:.3f}\")\n",
    "    print(f\"   • Regression model R²: {stats['model_r2']:.3f}\")\n",
    "\n",
    "print(f\"\\n✅ Generated {len(afforestation_results['artifacts'])} output files\")\n",
    "for artifact in afforestation_results['artifacts'][:3]:\n",
    "    print(f\"   • {artifact}\")\n",
    "if len(afforestation_results['artifacts']) > 3:\n",
    "    print(f\"   ... and {len(afforestation_results['artifacts'])-3} more\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Land Degradation Assessment\n",
    "\n",
    "Degradation hotspot identification and trend analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aeuz import degradation\n",
    "\n",
    "print(\"🏜️ Running Land Degradation Assessment...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "degradation_results = degradation.run()\n",
    "\n",
    "print(\"\\n📊 Degradation Analysis Summary:\")\n",
    "if 'summary_stats' in degradation_results:\n",
    "    stats = degradation_results['summary_stats']\n",
    "    print(f\"   • Average degradation score: {stats['avg_degradation_score']:.3f}\")\n",
    "    print(f\"   • Severe degradation areas: {stats['severe_degradation_areas']}\")\n",
    "    print(f\"   • High degradation areas: {stats['high_degradation_areas']}\")\n",
    "    print(f\"   • Hotspots identified: {stats['hotspots_identified']}\")\n",
    "    print(f\"   • Priority areas: {stats['priority_areas']}\")\n",
    "\n",
    "print(f\"\\n✅ Generated {len(degradation_results['artifacts'])} output files\")\n",
    "for artifact in degradation_results['artifacts'][:3]:\n",
    "    print(f\"   • {artifact}\")\n",
    "if len(degradation_results['artifacts']) > 3:\n",
    "    print(f\"   ... and {len(degradation_results['artifacts'])-3} more\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Riverbank Disturbance Analysis\n",
    "\n",
    "Buffer zone monitoring and disturbance mapping along water bodies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aeuz import riverbank\n",
    "\n",
    "print(\"🏞️ Running Riverbank Disturbance Analysis...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "riverbank_results = riverbank.run()\n",
    "\n",
    "print(\"\\n📊 Riverbank Analysis Summary:\")\n",
    "if 'summary_stats' in riverbank_results:\n",
    "    stats = riverbank_results['summary_stats']\n",
    "    print(f\"   • Total sites analyzed: {stats['total_sites']}\")\n",
    "    print(f\"   • High disturbance sites: {stats['high_disturbance_sites']}\")\n",
    "    print(f\"   • Average disturbance score: {stats['avg_disturbance_score']:.3f}\")\n",
    "    print(f\"   • Priority intervention sites: {stats['priority_sites']}\")\n",
    "    print(f\"   • Disturbance flags generated: {stats['disturbance_flags_generated']}\")\n",
    "\n",
    "print(f\"\\n✅ Generated {len(riverbank_results['artifacts'])} output files\")\n",
    "for artifact in riverbank_results['artifacts'][:3]:\n",
    "    print(f\"   • {artifact}\")\n",
    "if len(riverbank_results['artifacts']) > 3:\n",
    "    print(f\"   ... and {len(riverbank_results['artifacts'])-3} more\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Protected Area Monitoring\n",
    "\n",
    "Conservation status assessment and incident detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aeuz import protected_areas\n",
    "\n",
    "print(\"🏛️ Running Protected Area Monitoring...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "protected_results = protected_areas.run()\n",
    "\n",
    "print(\"\\n📊 Protected Areas Analysis Summary:\")\n",
    "if 'summary_stats' in protected_results:\n",
    "    stats = protected_results['summary_stats']\n",
    "    print(f\"   • Total protected areas: {stats['total_protected_areas']}\")\n",
    "    print(f\"   • Critical conservation areas: {stats['critical_areas']}\")\n",
    "    print(f\"   • Average disturbance index: {stats['avg_disturbance_index']:.3f}\")\n",
    "    print(f\"   • Incidents requiring attention: {stats['total_incidents']}\")\n",
    "    print(f\"   • Total protected area: {stats['total_protected_area_km2']:.0f} km²\")\n",
    "\n",
    "print(f\"\\n✅ Generated {len(protected_results['artifacts'])} output files\")\n",
    "for artifact in protected_results['artifacts'][:3]:\n",
    "    print(f\"   • {artifact}\")\n",
    "if len(protected_results['artifacts']) > 3:\n",
    "    print(f\"   ... and {len(protected_results['artifacts'])-3} more\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Biodiversity Analysis\n",
    "\n",
    "Ecosystem classification and habitat fragmentation assessment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aeuz import biodiversity\n",
    "\n",
    "print(\"🦋 Running Biodiversity Analysis...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "biodiversity_results = biodiversity.run()\n",
    "\n",
    "print(\"\\n📊 Biodiversity Analysis Summary:\")\n",
    "if 'summary_stats' in biodiversity_results:\n",
    "    stats = biodiversity_results['summary_stats']\n",
    "    print(f\"   • Average habitat quality: {stats['avg_habitat_quality']:.3f}\")\n",
    "    print(f\"   • Ecosystem types identified: {stats['ecosystem_types']}\")\n",
    "    print(f\"   • High diversity regions: {stats['high_diversity_regions']}\")\n",
    "    print(f\"   • Total samples analyzed: {stats['total_samples']}\")\n",
    "    print(f\"   • Most fragmented ecosystem: {stats['most_fragmented_ecosystem']}\")\n",
    "\n",
    "print(f\"\\n✅ Generated {len(biodiversity_results['artifacts'])} output files\")\n",
    "for artifact in biodiversity_results['artifacts'][:3]:\n",
    "    print(f\"   • {artifact}\")\n",
    "if len(biodiversity_results['artifacts']) > 3:\n",
    "    print(f\"   ... and {len(biodiversity_results['artifacts'])-3} more\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7 Urban Heat Island Analysis\n",
    "\n",
    "Heat island modeling and mitigation strategy development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aeuz import urban_heat\n",
    "\n",
    "print(\"🌡️ Running Urban Heat Island Analysis...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "urban_heat_results = urban_heat.run()\n",
    "\n",
    "print(\"\\n📊 Urban Heat Analysis Summary:\")\n",
    "if 'summary_stats' in urban_heat_results:\n",
    "    stats = urban_heat_results['summary_stats']\n",
    "    print(f\"   • Average land surface temperature: {stats['avg_lst']:.1f}°C\")\n",
    "    print(f\"   • Maximum UHI intensity: {stats['max_uhi_intensity']:.1f}°C\")\n",
    "    print(f\"   • High risk areas: {stats['high_risk_areas']}\")\n",
    "    print(f\"   • Total cooling potential: {stats['total_cooling_potential']:.1f}°C\")\n",
    "    print(f\"   • Model R²: {stats['model_r2']:.3f}\")\n",
    "    print(f\"   • Model RMSE: {stats['model_rmse']:.2f}°C\")\n",
    "\n",
    "print(f\"\\n✅ Generated {len(urban_heat_results['artifacts'])} output files\")\n",
    "for artifact in urban_heat_results['artifacts'][:3]:\n",
    "    print(f\"   • {artifact}\")\n",
    "if len(urban_heat_results['artifacts']) > 3:\n",
    "    print(f\"   ... and {len(urban_heat_results['artifacts'])-3} more\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Synthesis and Integration {#synthesis}\n",
    "\n",
    "Integrate results from all modules into a comprehensive regional assessment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aeuz import synthesis\n",
    "\n",
    "print(\"🔄 Running Comprehensive Synthesis...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "synthesis_results = synthesis.run()\n",
    "\n",
    "print(\"\\n📊 Synthesis Analysis Summary:\")\n",
    "if 'synthesis_summary' in synthesis_results:\n",
    "    summary = synthesis_results['synthesis_summary']\n",
    "    print(f\"   • Analysis timestamp: {summary['analysis_timestamp']}\")\n",
    "    print(f\"   • Modules completed: {summary['modules_completed']}/{summary['total_modules']}\")\n",
    "    \n",
    "    if 'investment_summary' in summary:\n",
    "        investment = summary['investment_summary']\n",
    "        print(f\"   • Total estimated cost: ${investment['total_estimated_cost']:,.0f}\")\n",
    "        print(f\"   • Priority investment areas: {len(investment['priority_investment_areas'])}\")\n",
    "    \n",
    "    if 'confidence_assessment' in summary:\n",
    "        confidence = summary['confidence_assessment']\n",
    "        print(f\"   • Data quality score: {confidence['data_quality_score']}%\")\n",
    "        print(f\"   • High confidence modules: {len(confidence['high_confidence_modules'])}\")\n",
    "\n",
    "print(f\"\\n✅ Generated {len(synthesis_results['artifacts'])} synthesis reports\")\n",
    "for artifact in synthesis_results['artifacts']:\n",
    "    print(f\"   • {artifact}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Quality Assurance {#qa}\n",
    "\n",
    "Comprehensive validation and quality assessment of all analysis outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aeuz import qa_module\n",
    "\n",
    "print(\"🔍 Running Quality Assurance Analysis...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "qa_results = qa_module.run()\n",
    "\n",
    "print(\"\\n📊 Quality Assurance Summary:\")\n",
    "if 'qa_summary' in qa_results:\n",
    "    qa_summary = qa_results['qa_summary']\n",
    "    status_emoji = \"✅\" if qa_summary['overall_status'] == 'PASS' else \"⚠️\" if qa_summary['overall_status'] == 'WARNING' else \"❌\"\n",
    "    \n",
    "    print(f\"   • Overall status: {status_emoji} {qa_summary['overall_status']}\")\n",
    "    print(f\"   • Files generated: {qa_summary['files_generated']}/{qa_summary['files_expected']}\")\n",
    "    print(f\"   • Quality score: {qa_summary['quality_score']:.1f}%\")\n",
    "    print(f\"   • Critical issues: {qa_summary['critical_issues']}\")\n",
    "    print(f\"   • Warnings: {qa_summary['warnings']}\")\n",
    "\n",
    "# Display QA report summary\n",
    "try:\n",
    "    qa_report_path = Path('qa/qa_report.md')\n",
    "    if qa_report_path.exists():\n",
    "        print(f\"\\n📋 QA Report available at: {qa_report_path}\")\n",
    "        \n",
    "        # Read and display key sections\n",
    "        with open(qa_report_path, 'r') as f:\n",
    "            content = f.read()\n",
    "            lines = content.split('\\n')\n",
    "            \n",
    "        # Find completion rates\n",
    "        print(\"\\n📈 Module Completion Rates:\")\n",
    "        in_table = False\n",
    "        for line in lines:\n",
    "            if 'Module | Expected Files | Generated Files | Completion Rate' in line:\n",
    "                in_table = True\n",
    "                continue\n",
    "            elif in_table and line.strip() and '|' in line and not line.startswith('|---'):\n",
    "                if line.count('|') >= 4:\n",
    "                    parts = [p.strip() for p in line.split('|')[1:-1]]\n",
    "                    if len(parts) >= 4:\n",
    "                        module, expected, generated, rate = parts[:4]\n",
    "                        rate_num = float(rate.replace('%', '')) if '%' in rate else 0\n",
    "                        status_icon = \"✅\" if rate_num == 100 else \"⚠️\" if rate_num >= 50 else \"❌\"\n",
    "                        print(f\"   {status_icon} {module}: {generated}/{expected} files ({rate})\")\n",
    "            elif in_table and not line.strip():\n",
    "                break\n",
    "                \n",
    "except Exception as e:\n",
    "    print(f\"Note: Could not read QA report details: {e}\")\n",
    "\n",
    "print(f\"\\n✅ QA analysis completed with {len(qa_results['artifacts'])} reports generated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Results Summary and Visualization {#results}\n",
    "\n",
    "Consolidated view of key findings across all analysis modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile all results\n",
    "all_results = {\n",
    "    'soil_moisture': soil_results,\n",
    "    'afforestation': afforestation_results,\n",
    "    'degradation': degradation_results,\n",
    "    'riverbank': riverbank_results,\n",
    "    'protected_areas': protected_results,\n",
    "    'biodiversity': biodiversity_results,\n",
    "    'urban_heat': urban_heat_results,\n",
    "    'synthesis': synthesis_results,\n",
    "    'qa': qa_results\n",
    "}\n",
    "\n",
    "print(\"📊 COMPREHENSIVE ANALYSIS RESULTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Summary statistics\n",
    "total_artifacts = sum(len(result.get('artifacts', [])) for result in all_results.values())\n",
    "successful_modules = sum(1 for result in all_results.values() if result.get('status') == 'ok')\n",
    "\n",
    "print(f\"\\n🎯 Overall Performance:\")\n",
    "print(f\"   • Successful modules: {successful_modules}/{len(all_results)}\")\n",
    "print(f\"   • Total artifacts generated: {total_artifacts}\")\n",
    "print(f\"   • Analysis completion: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "# Key findings from each module\n",
    "print(f\"\\n🔬 Key Findings by Module:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "findings_map = {\n",
    "    'soil_moisture': 'Water stress and soil moisture patterns',\n",
    "    'afforestation': 'Suitable sites for reforestation',\n",
    "    'degradation': 'Land degradation hotspots and trends',\n",
    "    'riverbank': 'Riverbank disturbance and buffer zones',\n",
    "    'protected_areas': 'Conservation status and incidents',\n",
    "    'biodiversity': 'Ecosystem diversity and fragmentation',\n",
    "    'urban_heat': 'Urban heat islands and mitigation'\n",
    "}\n",
    "\n",
    "for module, description in findings_map.items():\n",
    "    if module in all_results and 'summary_stats' in all_results[module]:\n",
    "        result = all_results[module]\n",
    "        status_icon = \"✅\" if result.get('status') == 'ok' else \"❌\"\n",
    "        artifact_count = len(result.get('artifacts', []))\n",
    "        print(f\"   {status_icon} {module.replace('_', ' ').title()}: {description}\")\n",
    "        print(f\"      Generated {artifact_count} output files\")\n",
    "        \n",
    "        # Show key metric for each module\n",
    "        stats = result['summary_stats']\n",
    "        if module == 'soil_moisture':\n",
    "            print(f\"      Key metric: {stats['severe_stress_areas']} severe water stress areas\")\n",
    "        elif module == 'afforestation':\n",
    "            print(f\"      Key metric: {stats['total_suitable_sites']} suitable sites identified\")\n",
    "        elif module == 'degradation':\n",
    "            print(f\"      Key metric: {stats['hotspots_identified']} degradation hotspots\")\n",
    "        elif module == 'riverbank':\n",
    "            print(f\"      Key metric: {stats['high_disturbance_sites']} high disturbance sites\")\n",
    "        elif module == 'protected_areas':\n",
    "            print(f\"      Key metric: {stats['total_incidents']} conservation incidents\")\n",
    "        elif module == 'biodiversity':\n",
    "            print(f\"      Key metric: {stats['ecosystem_types']} ecosystem types identified\")\n",
    "        elif module == 'urban_heat':\n",
    "            print(f\"      Key metric: {stats['avg_lst']:.1f}°C average temperature\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Regional Priority Assessment\n",
    "\n",
    "Compare environmental challenges across Uzbekistan's regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create regional comparison visualization\n",
    "regions = config['regions']\n",
    "\n",
    "print(\"🗺️ Regional Environmental Assessment:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Try to load regional data from CSV files\n",
    "regional_data = {}\n",
    "\n",
    "# List of regional CSV files to try to load\n",
    "regional_files = [\n",
    "    'alphaearth-uz/tables/soil_moisture_regional_summary.csv',\n",
    "    'alphaearth-uz/tables/biodiversity_regional_summary.csv',\n",
    "    'alphaearth-uz/tables/afforestation_regional_analysis.csv',\n",
    "    'alphaearth-uz/tables/degradation_regional_analysis.csv',\n",
    "    'alphaearth-uz/tables/urban_heat_regional_analysis.csv'\n",
    "]\n",
    "\n",
    "for file_path in regional_files:\n",
    "    try:\n",
    "        if Path(file_path).exists():\n",
    "            df = pd.read_csv(file_path)\n",
    "            module_name = file_path.split('/')[-1].split('_')[0]\n",
    "            regional_data[module_name] = df\n",
    "            print(f\"   ✅ Loaded {module_name} regional data ({len(df)} regions)\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ⚠️ Could not load {file_path}: {e}\")\n",
    "\n",
    "if regional_data:\n",
    "    print(f\"\\n📈 Creating regional comparison visualization...\")\n",
    "    \n",
    "    # Create a simple regional comparison plot\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    fig.suptitle('Regional Environmental Assessment - Uzbekistan', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    plot_idx = 0\n",
    "    \n",
    "    for module, data in regional_data.items():\n",
    "        if plot_idx >= 4:  # Only plot first 4 modules\n",
    "            break\n",
    "            \n",
    "        ax = axes[plot_idx // 2, plot_idx % 2]\n",
    "        \n",
    "        # Find a suitable column to plot\n",
    "        numeric_cols = data.select_dtypes(include=[np.number]).columns\n",
    "        region_col = None\n",
    "        \n",
    "        for col in data.columns:\n",
    "            if 'region' in col.lower():\n",
    "                region_col = col\n",
    "                break\n",
    "        \n",
    "        if region_col and len(numeric_cols) > 0:\n",
    "            # Use the first numeric column for plotting\n",
    "            y_col = numeric_cols[0]\n",
    "            \n",
    "            try:\n",
    "                # Create bar plot\n",
    "                bars = ax.bar(range(len(data)), data[y_col], alpha=0.7)\n",
    "                ax.set_xlabel('Regions')\n",
    "                ax.set_ylabel(y_col.replace('_', ' ').title())\n",
    "                ax.set_title(f'{module.title()} Analysis by Region')\n",
    "                ax.set_xticks(range(len(data)))\n",
    "                \n",
    "                # Try to use region names if available\n",
    "                if region_col in data.columns:\n",
    "                    labels = data[region_col].astype(str)\n",
    "                    ax.set_xticklabels(labels, rotation=45, ha='right')\n",
    "                else:\n",
    "                    ax.set_xticklabels([f'Region {i+1}' for i in range(len(data))], rotation=45)\n",
    "                    \n",
    "                # Add value labels on bars\n",
    "                for i, bar in enumerate(bars):\n",
    "                    height = bar.get_height()\n",
    "                    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                           f'{height:.2f}', ha='center', va='bottom', fontsize=8)\n",
    "                           \n",
    "            except Exception as e:\n",
    "                ax.text(0.5, 0.5, f'Error plotting {module}\\n{str(e)[:50]}...', \n",
    "                       ha='center', va='center', transform=ax.transAxes)\n",
    "                ax.set_title(f'{module.title()} Analysis (Error)')\n",
    "        else:\n",
    "            ax.text(0.5, 0.5, f'No suitable data\\nfor {module}', \n",
    "                   ha='center', va='center', transform=ax.transAxes)\n",
    "            ax.set_title(f'{module.title()} Analysis (No Data)')\n",
    "        \n",
    "        plot_idx += 1\n",
    "    \n",
    "    # Hide any unused subplots\n",
    "    for i in range(plot_idx, 4):\n",
    "        axes[i // 2, i % 2].set_visible(False)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"✅ Regional comparison visualization completed\")\n",
    "else:\n",
    "    print(\"⚠️ No regional data available for visualization\")\n",
    "\n",
    "print(f\"\\n📋 Summary: {len(regional_data)} regional datasets loaded and visualized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Output File Summary\n",
    "\n",
    "Comprehensive listing of all generated analysis outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive file inventory\n",
    "print(\"📁 GENERATED OUTPUT FILES\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "output_categories = {\n",
    "    'CSV Tables': [],\n",
    "    'PNG Figures': [],\n",
    "    'GeoJSON Files': [],\n",
    "    'Reports': [],\n",
    "    'QA Files': []\n",
    "}\n",
    "\n",
    "# Scan for all generated files\n",
    "for root, dirs, files in os.walk('.'):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "        \n",
    "        # Skip hidden files and cache\n",
    "        if file.startswith('.') or '__pycache__' in file_path:\n",
    "            continue\n",
    "            \n",
    "        if file.endswith('.csv'):\n",
    "            output_categories['CSV Tables'].append(file_path)\n",
    "        elif file.endswith('.png'):\n",
    "            output_categories['PNG Figures'].append(file_path)\n",
    "        elif file.endswith('.geojson'):\n",
    "            output_categories['GeoJSON Files'].append(file_path)\n",
    "        elif file.endswith('.md') or file.endswith('.json'):\n",
    "            if 'qa' in file_path.lower():\n",
    "                output_categories['QA Files'].append(file_path)\n",
    "            else:\n",
    "                output_categories['Reports'].append(file_path)\n",
    "\n",
    "# Display file inventory\n",
    "total_files = 0\n",
    "for category, files in output_categories.items():\n",
    "    if files:\n",
    "        print(f\"\\n📂 {category} ({len(files)} files):\")\n",
    "        for file_path in sorted(files)[:10]:  # Show first 10 files\n",
    "            file_size = os.path.getsize(file_path)\n",
    "            size_str = f\"{file_size:,} bytes\" if file_size < 1024*1024 else f\"{file_size/(1024*1024):.1f} MB\"\n",
    "            print(f\"   • {file_path} ({size_str})\")\n",
    "        \n",
    "        if len(files) > 10:\n",
    "            print(f\"   ... and {len(files)-10} more files\")\n",
    "        \n",
    "        total_files += len(files)\n",
    "\n",
    "print(f\"\\n📊 File Generation Summary:\")\n",
    "print(f\"   • Total files generated: {total_files}\")\n",
    "print(f\"   • CSV data tables: {len(output_categories['CSV Tables'])}\")\n",
    "print(f\"   • PNG visualizations: {len(output_categories['PNG Figures'])}\")\n",
    "print(f\"   • GeoJSON spatial data: {len(output_categories['GeoJSON Files'])}\")\n",
    "print(f\"   • Analysis reports: {len(output_categories['Reports'])}\")\n",
    "print(f\"   • QA documentation: {len(output_categories['QA Files'])}\")\n",
    "\n",
    "# Calculate total data size\n",
    "total_size = 0\n",
    "for category, files in output_categories.items():\n",
    "    for file_path in files:\n",
    "        try:\n",
    "            total_size += os.path.getsize(file_path)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "size_mb = total_size / (1024 * 1024)\n",
    "print(f\"   • Total data size: {size_mb:.1f} MB\")\n",
    "\n",
    "print(f\"\\n✅ All analysis outputs successfully generated and documented\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Final Publication and Documentation {#export}\n",
    "\n",
    "Generate final publication-ready reports and documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aeuz import publish\n",
    "\n",
    "print(\"📚 Running Final Publication Generation...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "publish_results = publish.run()\n",
    "\n",
    "print(\"\\n📊 Publication Summary:\")\n",
    "print(f\"   • Status: {publish_results.get('status', 'unknown')}\")\n",
    "print(f\"   • Reports generated: {len(publish_results.get('artifacts', []))}\")\n",
    "\n",
    "for artifact in publish_results.get('artifacts', []):\n",
    "    print(f\"   • {artifact}\")\n",
    "    \n",
    "    # Display excerpt from main report if available\n",
    "    if 'AlphaEarth_Uzbekistan_Report.md' in artifact:\n",
    "        try:\n",
    "            report_path = Path(artifact)\n",
    "            if report_path.exists():\n",
    "                with open(report_path, 'r') as f:\n",
    "                    content = f.read()\n",
    "                    lines = content.split('\\n')[:20]  # First 20 lines\n",
    "                    \n",
    "                print(\"\\n📄 Report Preview:\")\n",
    "                print(\"-\" * 30)\n",
    "                for line in lines:\n",
    "                    print(f\"   {line}\")\n",
    "                print(\"   ...\")\n",
    "                print(\"-\" * 30)\n",
    "        except Exception as e:\n",
    "            print(f\"   Note: Could not preview report: {e}\")\n",
    "\n",
    "print(f\"\\n✅ Publication generation completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Analysis Completion Summary\n",
    "\n",
    "Final summary and next steps for the comprehensive environmental analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final completion summary\n",
    "completion_time = datetime.now()\n",
    "\n",
    "print(\"🎉 ALPHAEARTH UZBEKISTAN ANALYSIS COMPLETE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\n⏰ Analysis Timeline:\")\n",
    "print(f\"   • Completion time: {completion_time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"   • Total modules executed: {len(modules)}\")\n",
    "print(f\"   • Total outputs generated: {total_files}\")\n",
    "\n",
    "print(f\"\\n🎯 Analysis Coverage:\")\n",
    "print(f\"   • Geographic scope: {config['country']} ({len(config['regions'])} regions)\")\n",
    "print(f\"   • Temporal scope: {config['time_window'][0]}-{config['time_window'][1]}\")\n",
    "print(f\"   • Environmental domains: 7 (soil, water, forests, degradation, biodiversity, urban, protected areas)\")\n",
    "print(f\"   • Analysis techniques: ML modeling, statistical analysis, geospatial analysis, trend detection\")\n",
    "\n",
    "print(f\"\\n📊 Quality Assessment:\")\n",
    "if 'qa_summary' in qa_results:\n",
    "    qa_summary = qa_results['qa_summary']\n",
    "    status_emoji = \"✅\" if qa_summary['overall_status'] == 'PASS' else \"⚠️\" if qa_summary['overall_status'] == 'WARNING' else \"❌\"\n",
    "    print(f\"   • Overall QA status: {status_emoji} {qa_summary['overall_status']}\")\n",
    "    print(f\"   • File completion rate: {qa_summary['files_generated']}/{qa_summary['files_expected']} ({qa_summary['quality_score']:.1f}%)\")\n",
    "    print(f\"   • Critical issues: {qa_summary['critical_issues']}\")\n",
    "    print(f\"   • Warnings: {qa_summary['warnings']}\")\n",
    "\n",
    "print(f\"\\n📁 Key Output Locations:\")\n",
    "print(f\"   • Data tables: alphaearth-uz/tables/ (CSV format)\")\n",
    "print(f\"   • Visualizations: alphaearth-uz/figs/ (PNG format)\")\n",
    "print(f\"   • Spatial data: alphaearth-uz/data_final/ (GeoJSON format)\")\n",
    "print(f\"   • Reports: alphaearth-uz/reports/ (Markdown/JSON format)\")\n",
    "print(f\"   • QA documentation: alphaearth-uz/qa/ (Markdown/JSON format)\")\n",
    "\n",
    "print(f\"\\n🔬 Research Applications:\")\n",
    "print(f\"   • Environmental monitoring and assessment\")\n",
    "print(f\"   • Land use planning and policy development\")\n",
    "print(f\"   • Climate change adaptation strategies\")\n",
    "print(f\"   • Conservation priority setting\")\n",
    "print(f\"   • Sustainable development planning\")\n",
    "\n",
    "print(f\"\\n📚 Recommended Next Steps:\")\n",
    "print(f\"   1. Review generated reports in alphaearth-uz/reports/\")\n",
    "print(f\"   2. Examine QA findings in alphaearth-uz/qa/qa_report.md\")\n",
    "print(f\"   3. Load spatial data (GeoJSON) into GIS software for mapping\")\n",
    "print(f\"   4. Analyze CSV tables for detailed regional comparisons\")\n",
    "print(f\"   5. Integrate findings into policy and planning documents\")\n",
    "print(f\"   6. Consider validation with ground-truth data where available\")\n",
    "print(f\"   7. Plan follow-up monitoring and regular analysis updates\")\n",
    "\n",
    "print(f\"\\n🌍 Impact Statement:\")\n",
    "print(f\"   This comprehensive analysis provides research-grade environmental\")\n",
    "print(f\"   assessment capabilities for Uzbekistan using cutting-edge satellite\")\n",
    "print(f\"   data and machine learning techniques. The results support evidence-\")\n",
    "print(f\"   based decision making for environmental management, conservation,\")\n",
    "print(f\"   and sustainable development across the country.\")\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 60)\n",
    "print(f\"✅ ANALYSIS PIPELINE EXECUTION SUCCESSFUL\")\n",
    "print(f\"   Thank you for using AlphaEarth Uzbekistan Analysis\")\n",
    "print(f\"\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Additional Information\n",
    "\n",
    "### Citation\n",
    "When using this analysis in research or policy documents, please cite:\n",
    "\n",
    "```\n",
    "AlphaEarth Uzbekistan Environmental Analysis (2025). \n",
    "Comprehensive environmental assessment using satellite embeddings and machine learning.\n",
    "Generated: [DATE]\n",
    "```\n",
    "\n",
    "### Technical Support\n",
    "- Review the `RUNBOOK.md` for operational procedures\n",
    "- Check `QA_PLAN.md` for quality assurance methodology\n",
    "- Examine `METADATA.md` for data specifications\n",
    "- Consult `CITATIONS.bib` for academic references\n",
    "\n",
    "### Data Access\n",
    "All generated outputs are available in the respective directories:\n",
    "- **Tables**: Machine-readable CSV files with analysis results\n",
    "- **Figures**: High-resolution PNG visualizations for reports\n",
    "- **Spatial Data**: GeoJSON files compatible with GIS software\n",
    "- **Reports**: Executive summaries and comprehensive documentation\n",
    "\n",
    "### Reproducibility\n",
    "This analysis is fully reproducible using the provided configuration and random seeds. All methods are documented and use open-source libraries.\n",
    "\n",
    "---\n",
    "\n",
    "*Generated by AlphaEarth Environmental Analysis Pipeline*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}